{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c7449c5b5bd47d490687a5e53d29522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13f47f81b1614636bfcb2bb3268dca7c",
              "IPY_MODEL_6f29b2d61b5740a681d0707febf8a57e",
              "IPY_MODEL_8fc1ffb3e8a84060857db068f281c654"
            ],
            "layout": "IPY_MODEL_59abf6f8ddd145f08b952b18e9d8393a"
          }
        },
        "13f47f81b1614636bfcb2bb3268dca7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d365ad3632d4da89a654939b1977221",
            "placeholder": "​",
            "style": "IPY_MODEL_c1769195d44d4678b32ca9a906b15fc0",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "6f29b2d61b5740a681d0707febf8a57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7227514a2a5343f286c9911232ea6a77",
            "max": 288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36dbe09bf97240c8ba113e151818ab2e",
            "value": 288
          }
        },
        "8fc1ffb3e8a84060857db068f281c654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a86aa1424e4191932b6f182ad1f207",
            "placeholder": "​",
            "style": "IPY_MODEL_719e7c387e5d41378af7f20a6e05d64b",
            "value": " 288/288 [00:37&lt;00:00,  6.86ba/s]"
          }
        },
        "59abf6f8ddd145f08b952b18e9d8393a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d365ad3632d4da89a654939b1977221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1769195d44d4678b32ca9a906b15fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7227514a2a5343f286c9911232ea6a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dbe09bf97240c8ba113e151818ab2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62a86aa1424e4191932b6f182ad1f207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719e7c387e5d41378af7f20a6e05d64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dee10690128475b91a15456a56c1539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a569946e317a4e1f8f6681bc11fb5c8c",
              "IPY_MODEL_99c563c02d8546b9b82fe06c008b31e0",
              "IPY_MODEL_624223a6a8794953a435fab2b14726ae"
            ],
            "layout": "IPY_MODEL_0ad916ef7be74cd7bc3d5b6ed8f3a936"
          }
        },
        "a569946e317a4e1f8f6681bc11fb5c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d24d5a6ff4c4cfc92c411337f5f7234",
            "placeholder": "​",
            "style": "IPY_MODEL_449290207ce04663b1625776fd5c2f7c",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "99c563c02d8546b9b82fe06c008b31e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f040cfcb4f34e02a81ee10750ee050b",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_160c5f6b44ec45b1aa3306045cec166a",
            "value": 14
          }
        },
        "624223a6a8794953a435fab2b14726ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e6d1d8ec4a454b870deca9f5a1833a",
            "placeholder": "​",
            "style": "IPY_MODEL_24dcdeb0022343c1b51488f534640a65",
            "value": " 14/14 [00:01&lt;00:00,  7.09ba/s]"
          }
        },
        "0ad916ef7be74cd7bc3d5b6ed8f3a936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d24d5a6ff4c4cfc92c411337f5f7234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449290207ce04663b1625776fd5c2f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f040cfcb4f34e02a81ee10750ee050b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160c5f6b44ec45b1aa3306045cec166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6e6d1d8ec4a454b870deca9f5a1833a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24dcdeb0022343c1b51488f534640a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68e1bce194f24257a68dd71ceccae93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d22fd650e2417a9f6b58f3818b8c6c",
              "IPY_MODEL_97092d99b3b1410fa6cb1ee36c0be274",
              "IPY_MODEL_376794c5911d494d9cbd2a25c22172d8"
            ],
            "layout": "IPY_MODEL_ddf4d1ce29f04f73b8d91f28a5620d2d"
          }
        },
        "e4d22fd650e2417a9f6b58f3818b8c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c7045e9b8448e4b117048621633902",
            "placeholder": "​",
            "style": "IPY_MODEL_17548fe1d2494b72b92498ac76d005d2",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "97092d99b3b1410fa6cb1ee36c0be274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab6b74953e7c46188de2fcc24aacf09c",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d611eaf7281a460797bc0d114e3fe1b0",
            "value": 12
          }
        },
        "376794c5911d494d9cbd2a25c22172d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9118bc37caba4d859cb1e793f848077c",
            "placeholder": "​",
            "style": "IPY_MODEL_dcff1ef376114cf7a1dcad22cbc4f43e",
            "value": " 12/12 [00:01&lt;00:00,  6.99ba/s]"
          }
        },
        "ddf4d1ce29f04f73b8d91f28a5620d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c7045e9b8448e4b117048621633902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17548fe1d2494b72b92498ac76d005d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6b74953e7c46188de2fcc24aacf09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d611eaf7281a460797bc0d114e3fe1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9118bc37caba4d859cb1e793f848077c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcff1ef376114cf7a1dcad22cbc4f43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TZJNf8WQOIR",
        "outputId": "d56860a7-93d3-428d-b1d2-0b6b3c477e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets rouge-score accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment & Setup —— Baseline Model"
      ],
      "metadata": {
        "id": "XpzWAweZWkgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Use baseline Model(FP32 baseline)"
      ],
      "metadata": {
        "id": "WPyOFBHQW2fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "### init model\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
        "\n",
        "print(\"Model loaded (FP32 baseline).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MPok2r5nQoD0",
        "outputId": "ff21fad4-6aa1-48b0-9742-894db0119076"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model loaded (FP32 baseline).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Load Dataset"
      ],
      "metadata": {
        "id": "JsLOQmuWk9Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "### Load dataset\n",
        "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "train_data = dataset[\"train\"]\n",
        "val_data   = dataset[\"validation\"]\n",
        "test_data  = dataset[\"test\"]\n",
        "\n",
        "train_data.to_csv(\"train.csv\")\n",
        "val_data.to_csv(\"val.csv\")\n",
        "test_data.to_csv(\"test.csv\")\n",
        "\n",
        "print(\"Dataset loaded:\")\n",
        "print(\"Train:\", len(train_data))\n",
        "print(\"Validation:\", len(val_data))\n",
        "print(\"Test:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "0c7449c5b5bd47d490687a5e53d29522",
            "13f47f81b1614636bfcb2bb3268dca7c",
            "6f29b2d61b5740a681d0707febf8a57e",
            "8fc1ffb3e8a84060857db068f281c654",
            "59abf6f8ddd145f08b952b18e9d8393a",
            "8d365ad3632d4da89a654939b1977221",
            "c1769195d44d4678b32ca9a906b15fc0",
            "7227514a2a5343f286c9911232ea6a77",
            "36dbe09bf97240c8ba113e151818ab2e",
            "62a86aa1424e4191932b6f182ad1f207",
            "719e7c387e5d41378af7f20a6e05d64b",
            "7dee10690128475b91a15456a56c1539",
            "a569946e317a4e1f8f6681bc11fb5c8c",
            "99c563c02d8546b9b82fe06c008b31e0",
            "624223a6a8794953a435fab2b14726ae",
            "0ad916ef7be74cd7bc3d5b6ed8f3a936",
            "7d24d5a6ff4c4cfc92c411337f5f7234",
            "449290207ce04663b1625776fd5c2f7c",
            "1f040cfcb4f34e02a81ee10750ee050b",
            "160c5f6b44ec45b1aa3306045cec166a",
            "f6e6d1d8ec4a454b870deca9f5a1833a",
            "24dcdeb0022343c1b51488f534640a65",
            "68e1bce194f24257a68dd71ceccae93e",
            "e4d22fd650e2417a9f6b58f3818b8c6c",
            "97092d99b3b1410fa6cb1ee36c0be274",
            "376794c5911d494d9cbd2a25c22172d8",
            "ddf4d1ce29f04f73b8d91f28a5620d2d",
            "71c7045e9b8448e4b117048621633902",
            "17548fe1d2494b72b92498ac76d005d2",
            "ab6b74953e7c46188de2fcc24aacf09c",
            "d611eaf7281a460797bc0d114e3fe1b0",
            "9118bc37caba4d859cb1e793f848077c",
            "dcff1ef376114cf7a1dcad22cbc4f43e"
          ]
        },
        "collapsed": true,
        "id": "SpTxUFSgQwuK",
        "outputId": "421ab0d6-11a8-4b05-aeff-dbf1703ff238"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/288 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c7449c5b5bd47d490687a5e53d29522"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dee10690128475b91a15456a56c1539"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68e1bce194f24257a68dd71ceccae93e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded:\n",
            "Train: 287113\n",
            "Validation: 13368\n",
            "Test: 11490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.⭐⭐⭐ Summarization Pipeline(重点研究)-(single request)"
      ],
      "metadata": {
        "id": "rpBVvr1VlaCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SUMMARY_LEN = 128\n",
        "NUM_BEAMS = 4\n",
        "WARMUP_ITERATIONS = 2\n",
        "\n",
        "def summarize_batch(texts, model, tokenizer, max_len=MAX_SUMMARY_LEN, num_beams=NUM_BEAMS):\n",
        "    \"\"\"\n",
        "    Single-request summarization using model.generate.\n",
        "    Returns a decoded string summary.\n",
        "    \"\"\"\n",
        "    # 统一输入格式\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "        return_single = True\n",
        "    else:\n",
        "        return_single = False\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=True  # 为批处理做准备\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs.get(\"attention_mask\", None),\n",
        "            num_beams=num_beams,\n",
        "            max_length=max_len,\n",
        "            early_stopping=True\n",
        "        )\n",
        "    summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in out_ids]\n",
        "\n",
        "    return summaries[0] if return_single else summaries\n",
        "\n",
        "# 为保持接口一致性，可以保留 summarize 作为别名\n",
        "summarize = summarize_batch\n"
      ],
      "metadata": {
        "id": "iSFYyPZ4SqBM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Build （Latency / Throughput / ROUGE） Tools"
      ],
      "metadata": {
        "id": "6RhJDvzRnKza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.1 ROUGE Scorer"
      ],
      "metadata": {
        "id": "s_IJXYNbnU2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "rouge = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
        "\n",
        "def eval_rouge(pred, ref):\n",
        "    score = rouge.score(ref, pred)\n",
        "    return {k: v.fmeasure for k, v in score.items()}\n"
      ],
      "metadata": {
        "id": "QVBPbNiXTiU_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.2 Latency"
      ],
      "metadata": {
        "id": "co8mzj7LnkoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_latency(text, model, tokenizer, warmup=True):\n",
        "    if warmup:\n",
        "        # 热身运行，避免第一次推理的冷启动影响\n",
        "        for _ in range(WARMUP_ITERATIONS):\n",
        "            _ = summarize(text, model, tokenizer)\n",
        "\n",
        "    # 正式测量\n",
        "    start_time = time.perf_counter()  # 使用更高精度的计时器\n",
        "    _ = summarize(text, model, tokenizer)\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    return end_time - start_time"
      ],
      "metadata": {
        "id": "CnStO4pzTnsd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.3 Throughput"
      ],
      "metadata": {
        "id": "4fITrYSpntZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_throughput_sequential(texts, model, tokenizer):\n",
        "    \"\"\"\n",
        "    顺序处理的吞吐量测量（作为对比参考）\n",
        "    \"\"\"\n",
        "    # 热身\n",
        "    _ = summarize(texts[0], model, tokenizer)\n",
        "\n",
        "    start_time = time.perf_counter()\n",
        "    for text in texts:\n",
        "        _ = summarize(text, model, tokenizer)\n",
        "    total_time = time.perf_counter() - start_time\n",
        "\n",
        "    return len(texts) / total_time"
      ],
      "metadata": {
        "id": "L18nKLu5nsAp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4 Total evaluate"
      ],
      "metadata": {
        "id": "twteg4FiwmIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_comprehensive(dataset, model, tokenizer, model_name=\"Unknown\"):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation function for model performance and quality\n",
        "\n",
        "    Args:\n",
        "        dataset: Test dataset\n",
        "        model: Model instance\n",
        "        tokenizer: Tokenizer instance\n",
        "        model_name: Model identifier name\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all evaluation metrics\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Starting evaluation for model: {model_name}\")\n",
        "\n",
        "    results = []\n",
        "    latencies = []\n",
        "    texts = [item[\"article\"] for item in dataset]\n",
        "\n",
        "    # 1. Measure latency and generate summaries\n",
        "    print(\"📊 Measuring latency and generating summaries...\")\n",
        "    for i, item in enumerate(dataset):\n",
        "        if i % 10 == 0:\n",
        "            print(f\"   Progress: {i}/{len(dataset)}\")\n",
        "\n",
        "        latency = measure_latency(item[\"article\"], model, tokenizer, warmup=(i==0))\n",
        "        latencies.append(latency)\n",
        "\n",
        "        pred = summarize(item[\"article\"], model, tokenizer)\n",
        "        results.append((pred, item[\"highlights\"]))\n",
        "\n",
        "    # 2. Calculate ROUGE scores\n",
        "    print(\"📈 Calculating ROUGE scores...\")\n",
        "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "\n",
        "    for pred, ref in results:\n",
        "        score = eval_rouge(pred, ref)\n",
        "        rouge_scores[\"rouge1\"].append(score[\"rouge1\"])\n",
        "        rouge_scores[\"rouge2\"].append(score[\"rouge2\"])\n",
        "        rouge_scores[\"rougeL\"].append(score[\"rougeL\"])\n",
        "\n",
        "    # 3. Measure throughput with different batch sizes\n",
        "    print(\"⚡ Measuring throughput...\")\n",
        "    throughput_sequential = measure_throughput_sequential(texts, model, tokenizer)\n",
        "\n",
        "    # 4. Calculate statistical metrics\n",
        "    import numpy as np\n",
        "    avg_latency = np.mean(latencies)\n",
        "    latency_std = np.std(latencies)\n",
        "\n",
        "    # Build results dictionary\n",
        "    evaluation_results = {\n",
        "        \"model_name\": model_name,\n",
        "        \"performance_metrics\": {\n",
        "            \"avg_latency_sec\": round(avg_latency, 4),\n",
        "            \"latency_std\": round(latency_std, 4),\n",
        "            \"throughput_sequential_req_per_sec\": round(throughput_sequential, 4),\n",
        "            \"min_latency\": round(np.min(latencies), 4),\n",
        "            \"max_latency\": round(np.max(latencies), 4),\n",
        "            \"p95_latency\": round(np.percentile(latencies, 95), 4)\n",
        "        },\n",
        "        \"quality_metrics\": {\n",
        "            \"rouge1\": round(np.mean(rouge_scores[\"rouge1\"]), 4),\n",
        "            \"rouge2\": round(np.mean(rouge_scores[\"rouge2\"]), 4),\n",
        "            \"rougeL\": round(np.mean(rouge_scores[\"rougeL\"]), 4),\n",
        "            \"rouge1_std\": round(np.std(rouge_scores[\"rouge1\"]), 4),\n",
        "            \"rouge2_std\": round(np.std(rouge_scores[\"rouge2\"]), 4),\n",
        "            \"rougeL_std\": round(np.std(rouge_scores[\"rougeL\"]), 4)\n",
        "        },\n",
        "        \"test_config\": {\n",
        "            \"sample_size\": len(dataset),\n",
        "            \"max_summary_length\": MAX_SUMMARY_LEN,\n",
        "            \"num_beams\": NUM_BEAMS,\n",
        "            \"device\": str(device)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"✅ Evaluation completed for {model_name}\")\n",
        "    return evaluation_results"
      ],
      "metadata": {
        "id": "MhoeGOIRwpcS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test: Prepare small test set"
      ],
      "metadata": {
        "id": "Uqd1koPeoTs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_NUM = 20\n",
        "def get_samples(ds, n=SAMPLE_NUM):\n",
        "    n = min(n, len(ds))\n",
        "    return ds.select(range(n))"
      ],
      "metadata": {
        "id": "i9Qyyim3SiKE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test = get_samples(test_data, SAMPLE_NUM)\n",
        "print(f\"[INFO] Using {len(small_test)} samples for baseline evaluation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esn8gzXhTuW2",
        "outputId": "8e1fdf6e-26d7-44b3-e58b-3c177574d058"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using 20 samples for baseline evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🌟🌟🌟 5.Bulid BaseLine"
      ],
      "metadata": {
        "id": "DUiuWxw_or-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# baseLine\n",
        "def run_baseline(dataset, model, tokenizer):\n",
        "    results = []\n",
        "    for item in dataset:\n",
        "        article = item[\"article\"]\n",
        "        ref = item[\"highlights\"]\n",
        "        pred = summarize(article, model, tokenizer)\n",
        "        results.append((pred, ref))\n",
        "    return results"
      ],
      "metadata": {
        "id": "TPzYFCwjVK9m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = run_baseline(small_test, model, tokenizer)\n",
        "print(\"Baseline inference finished.\")"
      ],
      "metadata": {
        "id": "T06DASLgVWty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ecc648-52a5-4997-f09b-1ca3863ca7fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline inference finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rouge_dataset(results):\n",
        "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
        "    for pred, ref in results:\n",
        "        score = eval_rouge(pred, ref)\n",
        "        rouge1_scores.append(score[\"rouge1\"])\n",
        "        rouge2_scores.append(score[\"rouge2\"])\n",
        "        rougeL_scores.append(score[\"rougeL\"])\n",
        "\n",
        "    return {\n",
        "        \"ROUGE-1\": sum(rouge1_scores)/len(rouge1_scores),\n",
        "        \"ROUGE-2\": sum(rouge2_scores)/len(rouge2_scores),\n",
        "        \"ROUGE-L\": sum(rougeL_scores)/len(rougeL_scores),\n",
        "    }\n",
        "\n",
        "baseline_rouge = evaluate_rouge_dataset(baseline_results)\n",
        "baseline_rouge"
      ],
      "metadata": {
        "id": "YVrr2b78VX7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7799d2d-9dec-4e07-88e7-ac36d2c63b52"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ROUGE-1': 0.35022025793945055,\n",
              " 'ROUGE-2': 0.1478972899837078,\n",
              " 'ROUGE-L': 0.2604310393319945}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "latencies = [measure_latency(item[\"article\"], model, tokenizer) for item in small_test]\n",
        "baseline_latency = np.mean(latencies)\n",
        "baseline_latency"
      ],
      "metadata": {
        "id": "EWjXrvx_VhiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a096c4-da50-41b4-848f-6b281c42e537"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.1165089720999049)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [item[\"article\"] for item in small_test]\n",
        "baseline_throughput = measure_throughput_sequential(texts, model, tokenizer)\n",
        "baseline_throughput"
      ],
      "metadata": {
        "id": "vDHKg4KsVk4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e1f2c3-b78e-4280-f892-b15bd29d5c0c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.893014765105986"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 6. Build  Baseline Report\n",
        "\n",
        "6.1 记录 Baseline 指标\n",
        "\n",
        "平均延迟（sec/request）\n",
        "\n",
        "吞吐量（req/sec）\n",
        "\n",
        "ROUGE-1/2/L 基线\n",
        "\n",
        "生成一份 baseline 报告（供优化对照）"
      ],
      "metadata": {
        "id": "zGgwT4twrnPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Build Baseline Report\n",
        "print(\"=== Generating Baseline Report ===\")\n",
        "\n",
        "baseline_results = evaluate_model_comprehensive(\n",
        "    dataset=small_test,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    model_name=\"BART-large-cnn FP32 Baseline\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"6.1 BASELINE METRICS REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"📊 Average Latency: {baseline_results['performance_metrics']['avg_latency_sec']} sec/request\")\n",
        "\n",
        "print(f\"⚡ Throughput (Sequential): {baseline_results['performance_metrics']['throughput_sequential_req_per_sec']} req/sec\")\n",
        "\n",
        "print(f\"🎯 ROUGE-1: {baseline_results['quality_metrics']['rouge1']}\")\n",
        "print(f\"🎯 ROUGE-2: {baseline_results['quality_metrics']['rouge2']}\")\n",
        "print(f\"🎯 ROUGE-L: {baseline_results['quality_metrics']['rougeL']}\")\n",
        "\n",
        "print(f\"📈 Latency Statistics:\")\n",
        "print(f\"   - Std: {baseline_results['performance_metrics']['latency_std']} sec\")\n",
        "print(f\"   - P95: {baseline_results['performance_metrics']['p95_latency']} sec\")\n",
        "print(f\"   - Min-Max: {baseline_results['performance_metrics']['min_latency']}-{baseline_results['performance_metrics']['max_latency']} sec\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"✅ Baseline report generated successfully!\")"
      ],
      "metadata": {
        "id": "U7uLo-E_tKmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd38b01e-6f1f-414f-c25f-a7f3b83a9bfd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating Baseline Report ===\n",
            "\n",
            "🔍 Starting evaluation for model: BART-large-cnn FP32 Baseline\n",
            "📊 Measuring latency and generating summaries...\n",
            "   Progress: 0/20\n",
            "   Progress: 10/20\n",
            "📈 Calculating ROUGE scores...\n",
            "⚡ Measuring throughput...\n",
            "✅ Evaluation completed for BART-large-cnn FP32 Baseline\n",
            "\n",
            "============================================================\n",
            "6.1 BASELINE METRICS REPORT\n",
            "============================================================\n",
            "📊 Average Latency: 1.119 sec/request\n",
            "⚡ Throughput (Sequential): 0.8825 req/sec\n",
            "🎯 ROUGE-1: 0.3502\n",
            "🎯 ROUGE-2: 0.1479\n",
            "🎯 ROUGE-L: 0.2604\n",
            "📈 Latency Statistics:\n",
            "   - Std: 0.2143 sec\n",
            "   - P95: 1.4664 sec\n",
            "   - Min-Max: 0.8487-1.5834 sec\n",
            "============================================================\n",
            "✅ Baseline report generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.1.2 save to report"
      ],
      "metadata": {
        "id": "n8oddee_xvwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# 保存基线结果到文件\n",
        "def save_baseline_report(results, filename=None):\n",
        "    if filename is None:\n",
        "        filename = f\"baseline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "\n",
        "    report = {\n",
        "        \"report_type\": \"baseline\",\n",
        "        \"generated_at\": datetime.now().isoformat(),\n",
        "        **results\n",
        "    }\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "    print(f\"📄 Baseline report saved to: {filename}\")\n",
        "    return filename\n",
        "\n",
        "# 保存基线报告\n",
        "report_file = save_baseline_report(baseline_results)"
      ],
      "metadata": {
        "id": "T9NK1jSxx020"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.2 记录模型在不同输入长度下的性能\n",
        "\n",
        "文章长度 vs latency 曲线"
      ],
      "metadata": {
        "id": "H12x6Q0FtEHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "length_buckets = [100, 200, 300, 400, 500, 600]\n",
        "\n",
        "def get_by_length(ds, target_len, tol=30):\n",
        "    samples = []\n",
        "    for item in ds:\n",
        "        if abs(len(tokenizer(item[\"article\"])[\"input_ids\"]) - target_len) < tol:\n",
        "            samples.append(item[\"article\"])\n",
        "        if len(samples) >= 5:\n",
        "            break\n",
        "    return samples\n",
        "\n",
        "bucket_latency = {}\n",
        "\n",
        "for L in length_buckets:\n",
        "    texts = get_by_length(test_data, L)\n",
        "    lat = [measure_latency(t, model, tokenizer) for t in texts]\n",
        "    bucket_latency[L] = np.mean(lat)\n",
        "plt.plot(list(bucket_latency.keys()), list(bucket_latency.values()))\n",
        "plt.xlabel(\"Input Length (tokens)\")\n",
        "plt.ylabel(\"Latency (sec)\")\n",
        "plt.title(\"Input Length vs Latency (FP32 Baseline)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ix6CQm1ztLLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "0218f941-d562-4550-c2f1-50a72f4f3211"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Optimization Phase"
      ],
      "metadata": {
        "id": "EPZ8DWO2uQdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "执行 PTQ（Post-Training Quantization）\n",
        "\n",
        "测试四种精度：\n",
        "\n",
        "FP32（baseline）\n",
        "\n",
        "FP16\n",
        "\n",
        "INT8\n",
        "\n",
        "INT4"
      ],
      "metadata": {
        "id": "RBH7gDTzv34G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 get models"
      ],
      "metadata": {
        "id": "t4FKe4PW24FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BitsAndBytesConfig, is_bitsandbytes_available\n",
        "\n",
        "def create_quantized_models(base_model_name=\"facebook/bart-large-cnn\", device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    创建优化后的不同精度版本 BART 模型，用于 GPU 推理。\n",
        "    \"\"\"\n",
        "    print(\"🔄 Creating optimized quantized models...\")\n",
        "    models = {}\n",
        "\n",
        "    # 检查 GPU\n",
        "    if not torch.cuda.is_available():\n",
        "        raise EnvironmentError(\"GPU not available. bitsandbytes INT8/INT4 requires GPU.\")\n",
        "\n",
        "    bnb_available = is_bitsandbytes_available(check_library_only=True)\n",
        "    if not bnb_available:\n",
        "        print(\"⚠️ bitsandbytes not available. INT8/INT4 models will be skipped.\")\n",
        "\n",
        "    # 1. FP32 baseline\n",
        "    print(\"   Loading FP32 baseline...\")\n",
        "    models['fp32'] = BartForConditionalGeneration.from_pretrained(\n",
        "        base_model_name,\n",
        "        torch_dtype=torch.float32\n",
        "    ).to(device)\n",
        "    models['fp32'].eval()\n",
        "\n",
        "    # 2. FP16 - 优化版本\n",
        "    print(\"   Creating optimized FP16 model...\")\n",
        "    models['fp16'] = BartForConditionalGeneration.from_pretrained(\n",
        "        base_model_name,\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True  # 减少CPU内存使用\n",
        "    ).to(device)\n",
        "    models['fp16'].eval()\n",
        "\n",
        "    # 3. INT8 (bitsandbytes) - 优化配置\n",
        "    models['int8'] = None\n",
        "    if bnb_available:\n",
        "        try:\n",
        "            print(\"   Creating optimized INT8 model...\")\n",
        "            bnb_config_8bit = BitsAndBytesConfig(\n",
        "                load_in_8bit=True,\n",
        "                llm_int8_enable_fp32_cpu_offload=True,  # 启用FP32 CPU卸载\n",
        "                llm_int8_skip_modules=None,  # 不跳过任何模块\n",
        "                llm_int8_threshold=6.0,      # 调整阈值\n",
        "                llm_int8_has_fp16_weight=False\n",
        "            )\n",
        "            models['int8'] = BartForConditionalGeneration.from_pretrained(\n",
        "                base_model_name,\n",
        "                quantization_config=bnb_config_8bit,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "            print(\"   ✅ INT8 model created successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ INT8 creation failed: {e}\")\n",
        "            # 回退到简化配置\n",
        "            try:\n",
        "                print(\"   🔄 Trying simplified INT8 config...\")\n",
        "                bnb_config_simple = BitsAndBytesConfig(load_in_8bit=True)\n",
        "                models['int8'] = BartForConditionalGeneration.from_pretrained(\n",
        "                    base_model_name,\n",
        "                    quantization_config=bnb_config_simple,\n",
        "                    device_map=\"auto\"\n",
        "                )\n",
        "                print(\"   ✅ INT8 model created with simple config\")\n",
        "            except Exception as e2:\n",
        "                print(f\"   ❌ INT8 failed completely: {e2}\")\n",
        "\n",
        "    # 4. INT4 (bitsandbytes) - 优化配置\n",
        "    models['int4'] = None\n",
        "    if bnb_available:\n",
        "        try:\n",
        "            print(\"   Creating optimized INT4 model...\")\n",
        "            bnb_config_4bit = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_use_double_quant=True,  # 启用双量化\n",
        "                bnb_4bit_quant_storage=torch.uint8\n",
        "            )\n",
        "            models['int4'] = BartForConditionalGeneration.from_pretrained(\n",
        "                base_model_name,\n",
        "                quantization_config=bnb_config_4bit,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "            print(\"   ✅ INT4 model created successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ INT4 creation failed: {e}\")\n",
        "            # 回退到简化配置\n",
        "            try:\n",
        "                print(\"   🔄 Trying simplified INT4 config...\")\n",
        "                bnb_config_simple_4bit = BitsAndBytesConfig(load_in_4bit=True)\n",
        "                models['int4'] = BartForConditionalGeneration.from_pretrained(\n",
        "                    base_model_name,\n",
        "                    quantization_config=bnb_config_simple_4bit,\n",
        "                    device_map=\"auto\"\n",
        "                )\n",
        "                print(\"   ✅ INT4 model created with simple config\")\n",
        "            except Exception as e2:\n",
        "                print(f\"   ❌ INT4 failed completely: {e2}\")\n",
        "\n",
        "    print(\"✅ All models loaded successfully!\")\n",
        "    return models"
      ],
      "metadata": {
        "id": "tti9i7tZv70N"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.2 测试不同模型的结果"
      ],
      "metadata": {
        "id": "IjNuSiKh5Btv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# 简洁循环版本\n",
        "print(\"=== Simplified Quantization Comparison ===\")\n",
        "models = create_quantized_models()\n",
        "\n",
        "#  逐个测试其他量化模型并与基线对比\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"=== Step 2: Testing Quantized Models vs Baseline ===\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "quantization_results = {}\n",
        "\n",
        "# 测试FP16\n",
        "print(f\"\\n🧪 Testing FP16 Model...\")\n",
        "fp16_results = evaluate_model_comprehensive(\n",
        "    dataset=small_test,\n",
        "    model=models['fp16'],\n",
        "    tokenizer=tokenizer,\n",
        "    model_name=\"BART-large-cnn FP16 Quantized\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== COMPARISON WITH BASELINE ===\")\n",
        "print(f\"Latency Improvement: {baseline_results['performance_metrics']['avg_latency_sec'] / fp16_results['performance_metrics']['avg_latency_sec']:.2f}x\")\n",
        "print(f\"Throughput Improvement: {fp16_results['performance_metrics']['throughput_sequential_req_per_sec'] / baseline_results['performance_metrics']['throughput_sequential_req_per_sec']:.2f}x\")\n",
        "print(f\"ROUGE-1 Change: {fp16_results['quality_metrics']['rouge1'] - baseline_results['quality_metrics']['rouge1']:+.4f}\")\n",
        "print(f\"ROUGE-L Change: {fp16_results['quality_metrics']['rougeL'] - baseline_results['quality_metrics']['rougeL']:+.4f}\")\n",
        "\n",
        "quantization_results['fp16'] = fp16_results\n",
        "\n",
        "# 测试INT8\n",
        "print(f\"\\n🧪 Testing INT8 Model...\")\n",
        "int8_results = evaluate_model_comprehensive(\n",
        "    dataset=small_test,\n",
        "    model=models['int8'],\n",
        "    tokenizer=tokenizer,\n",
        "    model_name=\"BART-large-cnn INT8 Quantized\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== COMPARISON WITH BASELINE ===\")\n",
        "print(f\"Latency Improvement: {baseline_results['performance_metrics']['avg_latency_sec'] / int8_results['performance_metrics']['avg_latency_sec']:.2f}x\")\n",
        "print(f\"Throughput Improvement: {int8_results['performance_metrics']['throughput_sequential_req_per_sec'] / baseline_results['performance_metrics']['throughput_sequential_req_per_sec']:.2f}x\")\n",
        "print(f\"ROUGE-1 Change: {int8_results['quality_metrics']['rouge1'] - baseline_results['quality_metrics']['rouge1']:+.4f}\")\n",
        "print(f\"ROUGE-L Change: {int8_results['quality_metrics']['rougeL'] - baseline_results['quality_metrics']['rougeL']:+.4f}\")\n",
        "\n",
        "quantization_results['int8'] = int8_results\n",
        "\n",
        "# 测试INT4（如果可用）\n",
        "if models['int4'] is not None:\n",
        "    print(f\"\\n🧪 Testing INT4 Model...\")\n",
        "    int4_results = evaluate_model_comprehensive(\n",
        "        dataset=small_test,\n",
        "        model=models['int4'],\n",
        "        tokenizer=tokenizer,\n",
        "        model_name=\"BART-large-cnn INT4 Quantized\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== COMPARISON WITH BASELINE ===\")\n",
        "    print(f\"Latency Improvement: {baseline_results['performance_metrics']['avg_latency_sec'] / int4_results['performance_metrics']['avg_latency_sec']:.2f}x\")\n",
        "    print(f\"Throughput Improvement: {int4_results['performance_metrics']['throughput_sequential_req_per_sec'] / baseline_results['performance_metrics']['throughput_sequential_req_per_sec']:.2f}x\")\n",
        "    print(f\"ROUGE-1 Change: {int4_results['quality_metrics']['rouge1'] - baseline_results['quality_metrics']['rouge1']:+.4f}\")\n",
        "    print(f\"ROUGE-L Change: {int4_results['quality_metrics']['rougeL'] - baseline_results['quality_metrics']['rougeL']:+.4f}\")\n",
        "\n",
        "    quantization_results['int4'] = int4_results\n",
        "else:\n",
        "    print(f\"\\n⚠️ Skipping INT4 - model not available\")\n",
        "\n",
        "# 3. 生成汇总对比报告\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"=== FINAL QUANTIZATION COMPARISON SUMMARY ===\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n📊 BASELINE (FP32):\")\n",
        "print(f\"   Latency: {baseline_results['performance_metrics']['avg_latency_sec']:.4f}s\")\n",
        "print(f\"   Throughput: {baseline_results['performance_metrics']['throughput_sequential_req_per_sec']:.2f} req/s\")\n",
        "print(f\"   ROUGE-L: {baseline_results['quality_metrics']['rougeL']:.4f}\")\n",
        "\n",
        "for precision, results in quantization_results.items():\n",
        "    latency_improvement = baseline_results['performance_metrics']['avg_latency_sec'] / results['performance_metrics']['avg_latency_sec']\n",
        "    throughput_improvement = results['performance_metrics']['throughput_sequential_req_per_sec'] / baseline_results['performance_metrics']['throughput_sequential_req_per_sec']\n",
        "    rougeL_change = results['quality_metrics']['rougeL'] - baseline_results['quality_metrics']['rougeL']\n",
        "\n",
        "    print(f\"\\n🎯 {precision.upper()}:\")\n",
        "    print(f\"   Latency: {results['performance_metrics']['avg_latency_sec']:.4f}s ({latency_improvement:.2f}x)\")\n",
        "    print(f\"   Throughput: {results['performance_metrics']['throughput_sequential_req_per_sec']:.2f} req/s ({throughput_improvement:.2f}x)\")\n",
        "    print(f\"   ROUGE-L: {results['quality_metrics']['rougeL']:.4f} ({rougeL_change:+.4f})\")\n",
        "\n",
        "# 4. 保存所有结果\n",
        "print(f\"\\n💾 Saving results...\")\n",
        "all_results = {\n",
        "    'baseline': baseline_results,\n",
        "    **quantization_results\n",
        "}\n",
        "\n",
        "# 保存到文件\n",
        "import json\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "with open(f\"quantization_comparison_{timestamp}.json\", 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(f\"✅ Results saved to: quantization_comparison_{timestamp}.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tbO1fza5BA9",
        "outputId": "080881ec-04ea-41cf-a582-fcc4ae8a86b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simplified Quantization Comparison ===\n",
            "🔄 Creating optimized quantized models...\n",
            "   Loading FP32 baseline...\n",
            "   Creating optimized FP16 model...\n",
            "   Creating optimized INT8 model...\n",
            "   ✅ INT8 model created successfully\n",
            "   Creating optimized INT4 model...\n",
            "   ✅ INT4 model created successfully\n",
            "✅ All models loaded successfully!\n",
            "\n",
            "================================================================================\n",
            "=== Step 2: Testing Quantized Models vs Baseline ===\n",
            "================================================================================\n",
            "\n",
            "🧪 Testing FP16 Model...\n",
            "\n",
            "🔍 Starting evaluation for model: BART-large-cnn FP16 Quantized\n",
            "📊 Measuring latency and generating summaries...\n",
            "   Progress: 0/20\n",
            "   Progress: 10/20\n",
            "📈 Calculating ROUGE scores...\n",
            "⚡ Measuring throughput...\n",
            "✅ Evaluation completed for BART-large-cnn FP16 Quantized\n",
            "\n",
            "=== COMPARISON WITH BASELINE ===\n",
            "Latency Improvement: 1.07x\n",
            "Throughput Improvement: 1.08x\n",
            "ROUGE-1 Change: +0.0029\n",
            "ROUGE-L Change: +0.0023\n",
            "\n",
            "🧪 Testing INT8 Model...\n",
            "\n",
            "🔍 Starting evaluation for model: BART-large-cnn INT8 Quantized\n",
            "📊 Measuring latency and generating summaries...\n",
            "   Progress: 0/20\n",
            "   Progress: 10/20\n",
            "📈 Calculating ROUGE scores...\n",
            "⚡ Measuring throughput...\n",
            "✅ Evaluation completed for BART-large-cnn INT8 Quantized\n",
            "\n",
            "=== COMPARISON WITH BASELINE ===\n",
            "Latency Improvement: 0.21x\n",
            "Throughput Improvement: 0.22x\n",
            "ROUGE-1 Change: -0.0016\n",
            "ROUGE-L Change: -0.0054\n",
            "\n",
            "🧪 Testing INT4 Model...\n",
            "\n",
            "🔍 Starting evaluation for model: BART-large-cnn INT4 Quantized\n",
            "📊 Measuring latency and generating summaries...\n",
            "   Progress: 0/20\n",
            "   Progress: 10/20\n",
            "📈 Calculating ROUGE scores...\n",
            "⚡ Measuring throughput...\n",
            "✅ Evaluation completed for BART-large-cnn INT4 Quantized\n",
            "\n",
            "=== COMPARISON WITH BASELINE ===\n",
            "Latency Improvement: 0.41x\n",
            "Throughput Improvement: 0.42x\n",
            "ROUGE-1 Change: +0.0179\n",
            "ROUGE-L Change: +0.0089\n",
            "\n",
            "================================================================================\n",
            "=== FINAL QUANTIZATION COMPARISON SUMMARY ===\n",
            "================================================================================\n",
            "\n",
            "📊 BASELINE (FP32):\n",
            "   Latency: 1.1190s\n",
            "   Throughput: 0.88 req/s\n",
            "   ROUGE-L: 0.2604\n",
            "\n",
            "🎯 FP16:\n",
            "   Latency: 1.0480s (1.07x)\n",
            "   Throughput: 0.95 req/s (1.08x)\n",
            "   ROUGE-L: 0.2627 (+0.0023)\n",
            "\n",
            "🎯 INT8:\n",
            "   Latency: 5.2063s (0.21x)\n",
            "   Throughput: 0.19 req/s (0.22x)\n",
            "   ROUGE-L: 0.2550 (-0.0054)\n",
            "\n",
            "🎯 INT4:\n",
            "   Latency: 2.7118s (0.41x)\n",
            "   Throughput: 0.37 req/s (0.42x)\n",
            "   ROUGE-L: 0.2693 (+0.0089)\n",
            "\n",
            "💾 Saving results...\n",
            "✅ Results saved to: quantization_comparison_20251116_110443.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"CUDA计算能力: {torch.cuda.get_device_capability()}\")\n",
        "# 需要计算能力 >= 6.1 才能获得INT8加速\n",
        "# 检查量化配置\n",
        "print(\"当前量化配置:\")\n",
        "print(f\"- 量化后端: {torch.backends.quantized.engine}\")\n",
        "print(f\"- 量化模式: 可能使用了不适合的量化策略\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHeDAVnXRANF",
        "outputId": "c3963b93-3c2a-48e6-9323-594adf40bb09"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA计算能力: (8, 9)\n",
            "当前量化配置:\n",
            "- 量化后端: x86\n",
            "- 量化模式: 可能使用了不适合的量化策略\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "动态批处理（Dynamic Batching）：在 batch size = 1,4,8,16 下测量延迟 / 吞吐 / ROUGE，并把量化与批处理结合比较。"
      ],
      "metadata": {
        "id": "xFURh1Eq9NTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_precision_batch_combination(self, models, batch_sizes=[1, 4, 8, 16], num_test_samples=50):\n",
        "        \"\"\"评估精度和批处理的组合效果\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"🔬 Starting Precision + Batch Size Optimization Experiment\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # 使用测试样本的子集\n",
        "        test_subset = self.dataset.select(range(min(num_test_samples, len(self.dataset))))\n",
        "        texts = [item[\"article\"] for item in test_subset]\n",
        "        references = [item[\"highlights\"] for item in test_subset]\n",
        "\n",
        "        all_results = []\n",
        "\n",
        "        for precision, model in models.items():\n",
        "            if model is None:\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n📊 Testing {precision.upper()} precision...\")\n",
        "\n",
        "            for batch_size in batch_sizes:\n",
        "                print(f\"   Batch size: {batch_size}\")\n",
        "\n",
        "                # 评估当前配置\n",
        "                result = self._evaluate_single_config(\n",
        "                    model=model,\n",
        "                    tokenizer=self.tokenizer,\n",
        "                    precision=precision,\n",
        "                    batch_size=batch_size,\n",
        "                    texts=texts,\n",
        "                    references=references\n",
        "                )\n",
        "\n",
        "                all_results.append(result)\n",
        "\n",
        "                # 打印当前结果\n",
        "                self._print_single_result(result)\n",
        "\n",
        "        # 保存所有结果\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        return results_df\n",
        "\n",
        "def _evaluate_single_config(self, model, tokenizer, precision, batch_size, texts, references):\n",
        "        \"\"\"评估单个配置（精度+批处理大小）\"\"\"\n",
        "\n",
        "        # 准备批量数据\n",
        "        batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
        "        reference_batches = [references[i:i + batch_size] for i in range(0, len(references), batch_size)]\n",
        "\n",
        "        # 预热\n",
        "        if len(batches) > 0:\n",
        "            _ = summarize_batch(batches[0], model, tokenizer)\n",
        "\n",
        "        # 测量延迟和吞吐量\n",
        "        start_time = time.perf_counter()\n",
        "        all_predictions = []\n",
        "\n",
        "        for batch in batches:\n",
        "            predictions = summarize_batch(batch, model, tokenizer)\n",
        "            if batch_size == 1:\n",
        "                all_predictions.extend([predictions] if isinstance(predictions, str) else predictions)\n",
        "            else:\n",
        "                all_predictions.extend(predictions)\n",
        "\n",
        "        total_time = time.perf_counter() - start_time\n",
        "\n",
        "        # 计算指标\n",
        "        total_samples = len(texts)\n",
        "        avg_latency = total_time / total_samples  # 平均每个样本的延迟\n",
        "        throughput = total_samples / total_time   # 总体吞吐量\n",
        "\n",
        "        # 计算ROUGE分数\n",
        "        rouge_scores = []\n",
        "        for pred, ref in zip(all_predictions, references):\n",
        "            score = eval_rouge(pred, ref)\n",
        "            rouge_scores.append(score)\n",
        "\n",
        "        avg_rouge1 = np.mean([s['rouge1'] for s in rouge_scores])\n",
        "        avg_rouge2 = np.mean([s['rouge2'] for s in rouge_scores])\n",
        "        avg_rougeL = np.mean([s['rougeL'] for s in rouge_scores])\n",
        "\n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'batch_size': batch_size,\n",
        "            'avg_latency_sec': round(avg_latency, 4),\n",
        "            'throughput_req_per_sec': round(throughput, 4),\n",
        "            'rouge1': round(avg_rouge1, 4),\n",
        "            'rouge2': round(avg_rouge2, 4),\n",
        "            'rougeL': round(avg_rougeL, 4),\n",
        "            'total_samples': total_samples,\n",
        "            'total_time_sec': round(total_time, 2)\n",
        "        }\n",
        "\n",
        "def _print_single_result(self, result):\n",
        "    \"\"\"打印单个配置的结果\"\"\"\n",
        "    print(f\"     ✅ Latency: {result['avg_latency_sec']:6.4f}s | \"\n",
        "          f\"Throughput: {result['throughput_req_per_sec']:6.2f} req/s | \"\n",
        "          f\"ROUGE-L: {result['rougeL']:.4f}\")\n",
        "\n",
        "def visualize_results(self, results_df):\n",
        "    \"\"\"可视化优化结果\"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # 创建多个子图\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Quantization + Batching Optimization Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. 延迟 vs 批处理大小（按精度）\n",
        "    for precision in results_df['precision'].unique():\n",
        "        precision_data = results_df[results_df['precision'] == precision]\n",
        "        axes[0,0].plot(precision_data['batch_size'], precision_data['avg_latency_sec'],\n",
        "                      'o-', label=precision.upper(), linewidth=2, markersize=8)\n",
        "\n",
        "    axes[0,0].set_xlabel('Batch Size')\n",
        "    axes[0,0].set_ylabel('Average Latency (sec/request)')\n",
        "    axes[0,0].set_title('Latency vs Batch Size by Precision')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. 吞吐量 vs 批处理大小（按精度）\n",
        "    for precision in results_df['precision'].unique():\n",
        "        precision_data = results_df[results_df['precision'] == precision]\n",
        "        axes[0,1].plot(precision_data['batch_size'], precision_data['throughput_req_per_sec'],\n",
        "                      'o-', label=precision.upper(), linewidth=2, markersize=8)\n",
        "\n",
        "    axes[0,1].set_xlabel('Batch Size')\n",
        "    axes[0,1].set_ylabel('Throughput (requests/sec)')\n",
        "    axes[0,1].set_title('Throughput vs Batch Size by Precision')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. ROUGE-L vs 批处理大小（按精度）\n",
        "    for precision in results_df['precision'].unique():\n",
        "        precision_data = results_df[results_df['precision'] == precision]\n",
        "        axes[1,0].plot(precision_data['batch_size'], precision_data['rougeL'],\n",
        "                      'o-', label=precision.upper(), linewidth=2, markersize=8)\n",
        "\n",
        "    axes[1,0].set_xlabel('Batch Size')\n",
        "    axes[1,0].set_ylabel('ROUGE-L Score')\n",
        "    axes[1,0].set_title('Quality (ROUGE-L) vs Batch Size by Precision')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. 延迟-质量权衡散点图\n",
        "    colors = {'fp32': 'red', 'fp16': 'blue', 'int8': 'green', 'int4': 'purple'}\n",
        "    for precision in results_df['precision'].unique():\n",
        "        precision_data = results_df[results_df['precision'] == precision]\n",
        "        axes[1,1].scatter(precision_data['avg_latency_sec'], precision_data['rougeL'],\n",
        "                        c=colors.get(precision, 'gray'), s=100, label=precision.upper(), alpha=0.7)\n",
        "\n",
        "        # 添加批处理大小标注\n",
        "        for _, row in precision_data.iterrows():\n",
        "            axes[1,1].annotate(f\"BS{row['batch_size']}\",\n",
        "                              (row['avg_latency_sec'], row['rougeL']),\n",
        "                              xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "\n",
        "    axes[1,1].set_xlabel('Latency (sec/request)')\n",
        "    axes[1,1].set_ylabel('ROUGE-L Score')\n",
        "    axes[1,1].set_title('Latency-Quality Trade-off')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_filename = f\"optimization_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return plot_filename"
      ],
      "metadata": {
        "id": "C42I9DD53i8f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}